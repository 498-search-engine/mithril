log_level=info

# Crawler storage paths
docs_directory=data/docs
state_directory=data/state
snapshot_directory=data/snapshot

dns_cache_size=100000

# Crawler config
workers=4
concurrent_requests=200

# Time between crawls on a single host
default_crawl_delay_ms=2000
# Rate limit bucket config (per addr)
ratelimit_bucket_ms=60000
ratelimit_bucket_count=60

# Middle queue internal configuration
middle_queue.queue_count=800
middle_queue.url_batch_size=10
middle_queue.host_url_limit=25
middle_queue.utilization_target=0.8

# robots.txt configuration
concurrent_robots_requests=400
robots_cache_size=50000

# Take snapshot of state every 30 minutes
snapshot_period_seconds=1800

# Seed urls, specified in seed_list.conf
seed_url_file=seed_list.conf

# Blacklisted hosts, specified in blacklisted_hosts.conf
blacklist_host_file=blacklisted_hosts.conf

# Prometheus metrics
metrics_port=9000

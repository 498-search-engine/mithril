log_level=info

# Crawler storage paths
docs_directory=data/docs
state_directory=data/state
snapshot_directory=data/snapshot

dns_cache_size=100000

# Crawler config
workers=6
concurrent_requests=150

# Time between crawls on a single host
default_crawl_delay_ms=2000

# Middle queue internal configuration
middle_queue.queue_count=400
middle_queue.url_batch_size=10
middle_queue.host_url_limit=25
middle_queue.utilization_target=0.5

# robots.txt configuration
concurrent_robots_requests=200
robots_cache_size=50000

# Take snapshot of state every 30 minutes
snapshot_period_seconds=1800

# Seed urls, specified in seed_list.conf
seed_url_file=seed_list.conf

# Blacklisted hosts, specified in blacklisted_hosts.conf
blacklist_host_file=blacklisted_hosts.conf

# Prometheus metrics
metrics_port=9000
